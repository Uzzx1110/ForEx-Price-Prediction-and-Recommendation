{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open_price</th>\n",
       "      <th>Day_high</th>\n",
       "      <th>Day_low</th>\n",
       "      <th>Closing_price</th>\n",
       "      <th>Currency Pair</th>\n",
       "      <th>Trend_Open_price</th>\n",
       "      <th>Seasonal_Open_price</th>\n",
       "      <th>Residual_Open_price</th>\n",
       "      <th>...</th>\n",
       "      <th>Seasonal_Day_low</th>\n",
       "      <th>Residual_Day_low</th>\n",
       "      <th>RSI</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>BB_Upper</th>\n",
       "      <th>BB_Lower</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-07</td>\n",
       "      <td>0.386891</td>\n",
       "      <td>0.384657</td>\n",
       "      <td>0.389693</td>\n",
       "      <td>0.386954</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.522182</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473615</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000055</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-11-10</td>\n",
       "      <td>0.387590</td>\n",
       "      <td>0.384752</td>\n",
       "      <td>0.389693</td>\n",
       "      <td>0.387558</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.557718</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460915</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000109</th>\n",
       "      <td>2</td>\n",
       "      <td>2014-11-11</td>\n",
       "      <td>0.387781</td>\n",
       "      <td>0.384248</td>\n",
       "      <td>0.390750</td>\n",
       "      <td>0.387641</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.533733</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475153</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000164</th>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>0.387641</td>\n",
       "      <td>0.384280</td>\n",
       "      <td>0.389757</td>\n",
       "      <td>0.386897</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.541190</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422273</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000219</th>\n",
       "      <td>4</td>\n",
       "      <td>2014-11-13</td>\n",
       "      <td>0.386752</td>\n",
       "      <td>0.384676</td>\n",
       "      <td>0.389757</td>\n",
       "      <td>0.388003</td>\n",
       "      <td>USD/INR</td>\n",
       "      <td>0.394461</td>\n",
       "      <td>0.534029</td>\n",
       "      <td>0.60751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456504</td>\n",
       "      <td>0.538767</td>\n",
       "      <td>64.491363</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.38654</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0.1        Date  Open_price  Day_high   Day_low  \\\n",
       "Unnamed: 0                                                             \n",
       "0.000000               0  2014-11-07    0.386891  0.384657  0.389693   \n",
       "0.000055               1  2014-11-10    0.387590  0.384752  0.389693   \n",
       "0.000109               2  2014-11-11    0.387781  0.384248  0.390750   \n",
       "0.000164               3  2014-11-12    0.387641  0.384280  0.389757   \n",
       "0.000219               4  2014-11-13    0.386752  0.384676  0.389757   \n",
       "\n",
       "            Closing_price Currency Pair  Trend_Open_price  \\\n",
       "Unnamed: 0                                                  \n",
       "0.000000         0.386954       USD/INR          0.394461   \n",
       "0.000055         0.387558       USD/INR          0.394461   \n",
       "0.000109         0.387641       USD/INR          0.394461   \n",
       "0.000164         0.386897       USD/INR          0.394461   \n",
       "0.000219         0.388003       USD/INR          0.394461   \n",
       "\n",
       "            Seasonal_Open_price  Residual_Open_price  ...  Seasonal_Day_low  \\\n",
       "Unnamed: 0                                            ...                     \n",
       "0.000000               0.522182              0.60751  ...          0.473615   \n",
       "0.000055               0.557718              0.60751  ...          0.460915   \n",
       "0.000109               0.533733              0.60751  ...          0.475153   \n",
       "0.000164               0.541190              0.60751  ...          0.422273   \n",
       "0.000219               0.534029              0.60751  ...          0.456504   \n",
       "\n",
       "            Residual_Day_low        RSI      MACD  MACD_Signal  BB_Upper  \\\n",
       "Unnamed: 0                                                                 \n",
       "0.000000            0.538767  64.491363  0.000000     0.000000  0.391812   \n",
       "0.000055            0.538767  64.491363  0.000048     0.000010  0.391812   \n",
       "0.000109            0.538767  64.491363  0.000092     0.000026  0.391812   \n",
       "0.000164            0.538767  64.491363  0.000066     0.000034  0.391812   \n",
       "0.000219            0.538767  64.491363  0.000133     0.000054  0.391812   \n",
       "\n",
       "            BB_Lower  day_of_week  month  is_weekend  \n",
       "Unnamed: 0                                            \n",
       "0.000000     0.38654            4     11           0  \n",
       "0.000055     0.38654            0     11           0  \n",
       "0.000109     0.38654            1     11           0  \n",
       "0.000164     0.38654            2     11           0  \n",
       "0.000219     0.38654            3     11           0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:/Users/uzmap/Documents/GitHub/ForEx/processed_data.csv',index_col='Unnamed: 0')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for currency pair: USD/INR\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0144 - val_loss: 7.9136e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0851e-04 - val_loss: 2.5073e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3650e-05 - val_loss: 8.5377e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1960e-05 - val_loss: 3.6630e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2048e-05 - val_loss: 3.6615e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8058e-05 - val_loss: 2.4076e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3521e-05 - val_loss: 2.1753e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9302e-05 - val_loss: 2.1149e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8886e-05 - val_loss: 1.6505e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7719e-05 - val_loss: 1.5767e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5333e-05 - val_loss: 1.6053e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4379e-05 - val_loss: 2.0312e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1850e-05 - val_loss: 1.2185e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2983e-05 - val_loss: 2.8074e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3438e-05 - val_loss: 1.8772e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2208e-05 - val_loss: 2.4056e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4781e-05 - val_loss: 1.8371e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2160e-05 - val_loss: 1.9761e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1982e-05 - val_loss: 2.8304e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1320e-05 - val_loss: 3.8694e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1399e-05 - val_loss: 1.1510e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.9893e-06 - val_loss: 2.2591e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0182e-05 - val_loss: 2.1227e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2985e-05 - val_loss: 7.1877e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.2210e-05 - val_loss: 1.2823e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.1833e-05 - val_loss: 2.6017e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.1554e-05 - val_loss: 6.2505e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.0615e-05 - val_loss: 1.4736e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.5797e-06 - val_loss: 2.3460e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.0007e-05 - val_loss: 6.1307e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.9102e-06 - val_loss: 1.9148e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.8591e-06 - val_loss: 6.2392e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.2715e-05 - val_loss: 3.2932e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.3127e-06 - val_loss: 2.7622e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.1177e-06 - val_loss: 4.8448e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.3115e-06 - val_loss: 6.9887e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.5317e-05 - val_loss: 4.5750e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 1.1433e-05 - val_loss: 3.5553e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.4698e-06 - val_loss: 5.9277e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.6872e-06 - val_loss: 3.9663e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.0217e-05 - val_loss: 4.4418e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.8599e-06 - val_loss: 1.9372e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.9861e-06 - val_loss: 4.7014e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 1.3761e-05 - val_loss: 7.4950e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 1.4974e-05 - val_loss: 5.2414e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.9507e-06 - val_loss: 3.7562e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.7464e-06 - val_loss: 4.6714e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.5927e-06 - val_loss: 5.4351e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.1495e-05 - val_loss: 5.0542e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 8.3934e-06 - val_loss: 7.9214e-06\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "Training model for currency pair: EUR/USD\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 3.7724e-04 - val_loss: 1.2397e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.1458e-05 - val_loss: 4.2992e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.8280e-06 - val_loss: 2.0196e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1.9618e-06 - val_loss: 1.3024e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.9705e-07 - val_loss: 5.2073e-07\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.8841e-07 - val_loss: 5.1444e-07\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.7944e-07 - val_loss: 3.9431e-07\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.4953e-07 - val_loss: 5.2058e-07\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.0647e-07 - val_loss: 3.1323e-07\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1430e-07 - val_loss: 3.2327e-07\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 3.0624e-07 - val_loss: 2.3567e-07\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.0422e-07 - val_loss: 2.2710e-07\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.2568e-07 - val_loss: 1.8392e-07\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.7673e-07 - val_loss: 1.6208e-07\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.9204e-07 - val_loss: 6.2036e-07\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 2.4446e-07 - val_loss: 1.3187e-07\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 2.0491e-07 - val_loss: 1.3564e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.4936e-07 - val_loss: 2.8839e-07\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 2.2555e-07 - val_loss: 6.3218e-07\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1876e-07 - val_loss: 3.1252e-07\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6991e-07 - val_loss: 4.5087e-07\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4316e-07 - val_loss: 2.5250e-07\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4301e-07 - val_loss: 1.2279e-07\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.3126e-07 - val_loss: 7.4026e-08\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8180e-07 - val_loss: 2.2827e-07\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3384e-07 - val_loss: 5.3976e-08\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9426e-07 - val_loss: 1.5422e-07\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7681e-07 - val_loss: 4.6151e-07\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4133e-07 - val_loss: 4.0083e-07\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2085e-07 - val_loss: 5.4312e-08\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4295e-07 - val_loss: 1.0087e-07\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6377e-07 - val_loss: 5.0458e-08\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9080e-07 - val_loss: 2.4728e-07\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7518e-07 - val_loss: 6.5014e-07\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9337e-07 - val_loss: 1.1326e-07\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3526e-07 - val_loss: 5.3675e-08\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7766e-07 - val_loss: 3.3479e-08\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9853e-07 - val_loss: 2.4931e-08\n",
      "Epoch 39/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2717e-07 - val_loss: 1.2901e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.5069e-07 - val_loss: 6.2435e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6476e-07 - val_loss: 1.0725e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0740e-07 - val_loss: 1.6906e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0189e-07 - val_loss: 1.6348e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3404e-06 - val_loss: 1.5263e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9451e-07 - val_loss: 9.5528e-08\n",
      "Epoch 46/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6868e-07 - val_loss: 9.3509e-08\n",
      "Epoch 47/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3127e-07 - val_loss: 3.1677e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3654e-07 - val_loss: 1.0674e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8476e-07 - val_loss: 1.4941e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.8634e-07 - val_loss: 8.3531e-07\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Training model for currency pair: GBP/USD\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 1.4823e-04 - val_loss: 6.1071e-06\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9290e-06 - val_loss: 1.6320e-06\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3337e-06 - val_loss: 1.0375e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3959e-06 - val_loss: 4.2389e-07\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0794e-06 - val_loss: 3.0093e-07\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1988e-07 - val_loss: 1.4039e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3864e-07 - val_loss: 5.5902e-07\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6800e-07 - val_loss: 1.8763e-07\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0742e-07 - val_loss: 1.7600e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2171e-06 - val_loss: 9.7581e-07\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.3137e-07 - val_loss: 8.7691e-07\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6712e-07 - val_loss: 4.4700e-07\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7661e-07 - val_loss: 5.5681e-07\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9924e-07 - val_loss: 3.6155e-07\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7753e-07 - val_loss: 3.5956e-07\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0171e-07 - val_loss: 7.5192e-08\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8127e-07 - val_loss: 1.1326e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5828e-07 - val_loss: 5.3108e-08\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5868e-07 - val_loss: 5.2946e-08\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5214e-07 - val_loss: 1.3389e-07\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.6361e-07 - val_loss: 4.4022e-07\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6044e-07 - val_loss: 4.6085e-08\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7470e-07 - val_loss: 1.1596e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.3825e-07 - val_loss: 2.7436e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2130e-07 - val_loss: 3.8594e-08\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0410e-07 - val_loss: 4.3563e-07\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0646e-07 - val_loss: 1.4140e-07\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2892e-07 - val_loss: 1.3442e-07\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2400e-07 - val_loss: 1.1127e-07\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1169e-07 - val_loss: 3.2245e-08\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9698e-07 - val_loss: 3.4393e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5860e-06 - val_loss: 7.3783e-08\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0685e-07 - val_loss: 2.2741e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3618e-07 - val_loss: 7.2479e-07\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5865e-07 - val_loss: 5.6848e-08\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5992e-07 - val_loss: 6.2652e-08\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0290e-07 - val_loss: 8.3496e-08\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8803e-07 - val_loss: 8.3761e-08\n",
      "Epoch 39/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4414e-07 - val_loss: 2.3850e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.9039e-07 - val_loss: 3.6836e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4257e-07 - val_loss: 5.6898e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9571e-07 - val_loss: 9.3078e-08\n",
      "Epoch 43/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.4704e-07 - val_loss: 8.3208e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.4640e-07 - val_loss: 1.9454e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4859e-06 - val_loss: 4.1084e-08\n",
      "Epoch 46/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5951e-07 - val_loss: 1.6933e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2636e-07 - val_loss: 2.1570e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5120e-07 - val_loss: 1.0661e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2273e-07 - val_loss: 1.0319e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1394e-07 - val_loss: 1.0313e-07\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Training model for currency pair: USD/JPY\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1941 - val_loss: 0.0099\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.1349e-04 - val_loss: 0.0026\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4336e-04 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5399e-04 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0150e-04 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0539e-04 - val_loss: 0.0021\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0935e-04 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6307e-04 - val_loss: 0.0020\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5383e-04 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3021e-04 - val_loss: 0.0023\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9262e-04 - val_loss: 0.0019\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1696e-04 - val_loss: 0.0019\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5608e-04 - val_loss: 0.0019\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7920e-05 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3030e-05 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5231e-04 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4438e-05 - val_loss: 0.0018\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6004e-05 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4957e-04 - val_loss: 0.0018\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4909e-05 - val_loss: 0.0018\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6808e-05 - val_loss: 0.0018\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0887e-04 - val_loss: 0.0017\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0448e-05 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2756e-04 - val_loss: 0.0017\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5444e-05 - val_loss: 0.0017\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0268e-04 - val_loss: 0.0017\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2038e-04 - val_loss: 0.0017\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0437e-04 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4249e-04 - val_loss: 0.0017\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4752e-04 - val_loss: 0.0018\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6009e-05 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4805e-04 - val_loss: 0.0016\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4157e-05 - val_loss: 0.0016\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2842e-05 - val_loss: 0.0016\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0228e-04 - val_loss: 0.0016\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0382e-04 - val_loss: 0.0016\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9759e-05 - val_loss: 0.0017\n",
      "Epoch 39/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0262e-04 - val_loss: 0.0018\n",
      "Epoch 40/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4934e-05 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3763e-04 - val_loss: 0.0016\n",
      "Epoch 42/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1249e-04 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1675e-05 - val_loss: 0.0017\n",
      "Epoch 44/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3402e-04 - val_loss: 0.0015\n",
      "Epoch 45/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2690e-04 - val_loss: 0.0015\n",
      "Epoch 46/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5849e-05 - val_loss: 0.0015\n",
      "Epoch 47/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3848e-04 - val_loss: 0.0015\n",
      "Epoch 48/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6108e-05 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6904e-05 - val_loss: 0.0015\n",
      "Epoch 50/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5048e-05 - val_loss: 0.0015\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Training model for currency pair: EUR/INR\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0964 - val_loss: 0.0021\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3799e-04 - val_loss: 8.3727e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.6398e-04 - val_loss: 3.5529e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8884e-04 - val_loss: 8.3150e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.2716e-05 - val_loss: 4.7701e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.6430e-05 - val_loss: 3.4543e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.7924e-05 - val_loss: 3.0954e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4645e-05 - val_loss: 2.8411e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8742e-05 - val_loss: 2.9932e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5175e-05 - val_loss: 4.4942e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3530e-05 - val_loss: 2.1850e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5817e-05 - val_loss: 2.0543e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.4009e-05 - val_loss: 1.9474e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1452e-05 - val_loss: 3.0326e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4470e-05 - val_loss: 2.7975e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4429e-05 - val_loss: 1.8840e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0644e-05 - val_loss: 1.6723e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9615e-05 - val_loss: 1.9692e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0434e-05 - val_loss: 1.6112e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0502e-05 - val_loss: 2.7638e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1013e-05 - val_loss: 1.5999e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8926e-05 - val_loss: 1.8209e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9446e-05 - val_loss: 2.2442e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2778e-05 - val_loss: 1.4504e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7769e-05 - val_loss: 4.5289e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1619e-05 - val_loss: 2.1460e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9297e-05 - val_loss: 1.5913e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0551e-05 - val_loss: 1.5365e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7034e-05 - val_loss: 4.0356e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8853e-05 - val_loss: 1.4556e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6637e-05 - val_loss: 1.6579e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8794e-05 - val_loss: 1.4844e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7152e-05 - val_loss: 3.1522e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7455e-05 - val_loss: 1.8847e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7556e-05 - val_loss: 1.9534e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6550e-05 - val_loss: 1.8444e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2767e-05 - val_loss: 2.7418e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6579e-05 - val_loss: 1.4657e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6601e-05 - val_loss: 1.2368e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5480e-05 - val_loss: 1.2549e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4954e-05 - val_loss: 1.4761e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5505e-05 - val_loss: 1.2849e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7323e-05 - val_loss: 2.2223e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.9765e-05 - val_loss: 3.3861e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4773e-05 - val_loss: 1.4507e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5837e-05 - val_loss: 1.1755e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2821e-05 - val_loss: 1.4807e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6833e-05 - val_loss: 1.1947e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6706e-05 - val_loss: 1.4167e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4942e-05 - val_loss: 1.3891e-05\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Training model for currency pair: JPY/INR\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0017 - val_loss: 2.0318e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3989e-05 - val_loss: 1.2922e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1959e-06 - val_loss: 8.3206e-06\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8245e-06 - val_loss: 5.3688e-06\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5309e-06 - val_loss: 3.8847e-06\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5104e-06 - val_loss: 3.5493e-06\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0967e-06 - val_loss: 2.3625e-06\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7308e-06 - val_loss: 2.3546e-06\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4814e-06 - val_loss: 2.5605e-06\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3172e-06 - val_loss: 1.9234e-06\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1525e-06 - val_loss: 1.5495e-06\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0353e-06 - val_loss: 1.6075e-06\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0270e-06 - val_loss: 1.4202e-06\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.8837e-07 - val_loss: 1.3984e-06\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5405e-07 - val_loss: 1.0508e-06\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3892e-07 - val_loss: 1.3416e-06\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.7694e-07 - val_loss: 1.0388e-06\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5858e-07 - val_loss: 1.1855e-06\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8516e-07 - val_loss: 1.1243e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2497e-07 - val_loss: 7.9239e-07\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.8476e-07 - val_loss: 7.7250e-07\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4425e-07 - val_loss: 7.0926e-07\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0214e-07 - val_loss: 7.4914e-07\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6675e-07 - val_loss: 6.1686e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.5533e-07 - val_loss: 6.7357e-07\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.0302e-07 - val_loss: 6.0811e-07\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6489e-07 - val_loss: 1.1399e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.7652e-07 - val_loss: 6.6762e-07\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.4924e-07 - val_loss: 4.8160e-07\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2336e-07 - val_loss: 4.5435e-07\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3848e-07 - val_loss: 5.0240e-07\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9993e-07 - val_loss: 4.0301e-07\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7950e-07 - val_loss: 4.1171e-07\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5924e-07 - val_loss: 3.8682e-07\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8030e-07 - val_loss: 3.4001e-07\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6218e-07 - val_loss: 4.3326e-07\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2682e-07 - val_loss: 4.0561e-07\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4928e-07 - val_loss: 3.6749e-07\n",
      "Epoch 39/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0269e-07 - val_loss: 3.6276e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.2586e-07 - val_loss: 2.5890e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7613e-07 - val_loss: 2.5721e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7704e-07 - val_loss: 2.4018e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6547e-07 - val_loss: 2.4039e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7982e-07 - val_loss: 3.9205e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.6900e-07 - val_loss: 2.5489e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5046e-07 - val_loss: 2.1131e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4210e-07 - val_loss: 2.4259e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3473e-07 - val_loss: 2.6162e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5301e-07 - val_loss: 3.8801e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6796e-07 - val_loss: 5.8236e-07\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Training model for currency pair: GBP/INR\n",
      "Epoch 1/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0214 - val_loss: 0.0018\n",
      "Epoch 2/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.6174e-04 - val_loss: 0.0013\n",
      "Epoch 3/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3438e-04 - val_loss: 8.1483e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5669e-04 - val_loss: 6.6610e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6836e-04 - val_loss: 2.5791e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8822e-04 - val_loss: 1.4701e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2395e-04 - val_loss: 8.5686e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.9523e-05 - val_loss: 9.6079e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3310e-05 - val_loss: 6.4698e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.6653e-05 - val_loss: 6.0443e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4839e-05 - val_loss: 1.1657e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1243e-05 - val_loss: 6.7582e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9852e-05 - val_loss: 6.0190e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7934e-05 - val_loss: 5.2906e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4165e-05 - val_loss: 7.1355e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1390e-05 - val_loss: 6.9088e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.3078e-05 - val_loss: 3.5890e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.4007e-05 - val_loss: 3.7172e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9759e-05 - val_loss: 2.8928e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.9558e-05 - val_loss: 2.9098e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8567e-05 - val_loss: 3.6759e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5777e-05 - val_loss: 3.2314e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2896e-05 - val_loss: 2.5688e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4855e-05 - val_loss: 2.1444e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5759e-05 - val_loss: 3.3052e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5125e-05 - val_loss: 7.1531e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.8237e-05 - val_loss: 1.9483e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.5929e-05 - val_loss: 3.3408e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2512e-05 - val_loss: 1.2380e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.2747e-05 - val_loss: 1.6898e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9968e-05 - val_loss: 1.8059e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1817e-05 - val_loss: 4.1216e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8582e-05 - val_loss: 3.2181e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6473e-05 - val_loss: 2.6428e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0149e-05 - val_loss: 1.3908e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0143e-05 - val_loss: 2.0154e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9612e-05 - val_loss: 1.4301e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7828e-05 - val_loss: 1.7799e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5.0547e-05 - val_loss: 5.5088e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8190e-05 - val_loss: 3.0916e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6741e-05 - val_loss: 1.3224e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5757e-05 - val_loss: 1.5759e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3970e-05 - val_loss: 1.4290e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.7318e-05 - val_loss: 3.0797e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0735e-05 - val_loss: 1.3053e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4782e-05 - val_loss: 8.9104e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1749e-05 - val_loss: 1.2142e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.5150e-05 - val_loss: 1.6117e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2405e-05 - val_loss: 1.5465e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2113e-05 - val_loss: 1.2367e-05\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Results for GBP/INR - MAE: 0.0028100060247652735, MAPE: 0.003944179294775948, R^2: 0.9721238089631284\n",
      "\n",
      "Final Results for Each Currency Pair:\n",
      "USD/INR - MAE: 0.0023307329883217763, MAPE: 0.004116125858575293, R^2: 0.6163930701222106\n",
      "True values (sample): [0.56308075 0.56526441 0.56444726 0.56405584 0.5636095 ]\n",
      "Predicted values (sample): [0.56264853 0.5630031  0.5639533  0.5641131  0.5640417 ]\n",
      "\n",
      "EUR/USD - MAE: 0.0009031166620508276, MAPE: 0.22830830690546483, R^2: -73.64689865365673\n",
      "True values (sample): [0.00375358 0.00381188 0.003846   0.00382149 0.00378331]\n",
      "Predicted values (sample): [0.00477738 0.00492124 0.00485745 0.00481127 0.0047856 ]\n",
      "\n",
      "GBP/USD - MAE: 0.0002970573209964444, MAPE: 0.058024440898520054, R^2: -1.2585754968134277\n",
      "True values (sample): [0.00494093 0.00499992 0.00504297 0.0048849  0.00486505]\n",
      "Predicted values (sample): [0.00502615 0.00508753 0.00514418 0.00531609 0.00541041]\n",
      "\n",
      "USD/JPY - MAE: 0.021960889816194942, MAPE: 0.026029084418826814, R^2: 0.8194284937342837\n",
      "True values (sample): [0.94073879 0.92755437 0.92593385 0.94243498 0.93514914]\n",
      "Predicted values (sample): [0.9286041  0.9277212  0.9244173  0.92725503 0.9347513 ]\n",
      "\n",
      "EUR/INR - MAE: 0.002921792518383696, MAPE: 0.0047635760612984865, R^2: 0.8642307735162928\n",
      "True values (sample): [0.59729156 0.60074561 0.60047093 0.59694822 0.59775164]\n",
      "Predicted values (sample): [0.59154344 0.5938108  0.59532547 0.5964443  0.5961576 ]\n",
      "\n",
      "JPY/INR - MAE: 0.0006612343658047155, MAPE: 2.063027358893352, R^2: -13.055952806087491\n",
      "True values (sample): [0.00068593 0.00069651 0.00064185 0.00067968 0.00065956]\n",
      "Predicted values (sample): [0.00161702 0.00170566 0.0020013  0.00211607 0.00195784]\n",
      "\n",
      "GBP/INR - MAE: 0.0028100060247652735, MAPE: 0.003944179294775948, R^2: 0.9721238089631284\n",
      "True values (sample): [0.70051594 0.68904344 0.6883183  0.6856924  0.68736586]\n",
      "Predicted values (sample): [0.6907846  0.6917741  0.68620217 0.6854945  0.68744904]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Convert Date column to datetime (if necessary)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# List of unique currency pairs\n",
    "currency_pairs = data['Currency Pair'].unique()\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length, :-1])  # Use all features except the target\n",
    "        y.append(data[i+seq_length, -1])     # The target variable\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Dictionary to store evaluation metrics for each currency pair\n",
    "results = {}\n",
    "\n",
    "# Hyperparameters\n",
    "SEQ_LENGTH = 30  # Number of time steps in each sequence\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Loop over each currency pair\n",
    "for pair in currency_pairs:\n",
    "    print(f\"Training model for currency pair: {pair}\")\n",
    "    \n",
    "    # Filter data for the current currency pair\n",
    "    pair_data = data[data['Currency Pair'] == pair]\n",
    "    \n",
    "    # Sort by date to ensure proper time series order\n",
    "    pair_data = pair_data.sort_values('Date')\n",
    "    \n",
    "    # Select features and target (Closing price is the target)\n",
    "    features = pair_data[['Open_price', 'Day_high', 'Day_low', 'RSI', 'MACD', 'Trend_Open_price', 'Seasonal_Open_price', 'Residual_Open_price', 'BB_Upper', 'BB_Lower']]\n",
    "    target = pair_data['Closing_price']\n",
    "    \n",
    "    # Combine features and target for sequence creation\n",
    "    data_combined = pd.concat([features, target], axis=1).values\n",
    "    \n",
    "    # Split data into train and test sets (80-20 split)\n",
    "    split_idx = int(len(data_combined) * 0.8)\n",
    "    train_data = data_combined[:split_idx]\n",
    "    test_data = data_combined[split_idx:]\n",
    "\n",
    "    # Create sequences\n",
    "    X_train, y_train = create_sequences(train_data, SEQ_LENGTH)\n",
    "    X_test, y_test = create_sequences(test_data, SEQ_LENGTH)\n",
    "    \n",
    "    # Build LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test), verbose=1)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Store the results for this currency pair\n",
    "#     results[pair] = {\n",
    "#         'MAE': mae,\n",
    "#         'MAPE': mape,\n",
    "#         'R^2': r2\n",
    "#     }\n",
    "    \n",
    "#     print(f\"Results for {pair} - MAE: {mae}, MAPE: {mape}, R^2: {r2}\")\n",
    "\n",
    "# # Display final results for each currency pair\n",
    "# print(\"\\nFinal Results for Each Currency Pair:\")\n",
    "# for pair, metrics in results.items():\n",
    "#     print(f\"{pair} - MAE: {metrics['MAE']}, MAPE: {metrics['MAPE']}, R^2: {metrics['R^2']}\")\n",
    "    \n",
    " \n",
    "    # Store the results and predictions for this currency pair\n",
    "    results[pair] = {\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'R^2': r2,\n",
    "        'y_true': y_test,       # True values for the test set\n",
    "        'y_pred': y_pred_test    # Predicted values for the test set\n",
    "    }\n",
    "    \n",
    "print(f\"Results for {pair} - MAE: {mae}, MAPE: {mape}, R^2: {r2}\")\n",
    "\n",
    "# Display final results and predictions for each currency pair\n",
    "print(\"\\nFinal Results for Each Currency Pair:\")\n",
    "for pair, metrics in results.items():\n",
    "    print(f\"{pair} - MAE: {metrics['MAE']}, MAPE: {metrics['MAPE']}, R^2: {metrics['R^2']}\")\n",
    "    print(f\"True values (sample): {metrics['y_true'][:5].flatten()}\")\n",
    "    print(f\"Predicted values (sample): {metrics['y_pred'][:5].flatten()}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
